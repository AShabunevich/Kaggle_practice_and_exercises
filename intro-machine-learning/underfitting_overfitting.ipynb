{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Same code that was used in 'model_validation.ipynb'.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MAE: 29652.931506849316\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#path to access file\n",
    "file_path = '~/Desktop/Kaggle/practice/model_validation_home_train.csv'\n",
    "#reads file\n",
    "file_data = pd.read_csv(file_path)\n",
    "\n",
    "#prediction target\n",
    "y = file_data.SalePrice\n",
    "#features that determines house price\n",
    "featured_columns = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = file_data[featured_columns]\n",
    "\n",
    "#split data into training and validation\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "\n",
    "#specify model\n",
    "file_model = DecisionTreeRegressor(random_state=1)\n",
    "#fit model with trining data set\n",
    "file_model.fit(train_X, train_y)\n",
    "\n",
    "#predict validation prices based on model that used train data\n",
    "valid_predict = file_model.predict(val_X)\n",
    "\n",
    "#calculate MAE\n",
    "mae2 = mean_absolute_error(val_y, valid_predict)\n",
    "print('MAE:', mae2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To improve this model, we need to determine the lowest MAE based on the tree leaves. The best MAE can be determined from model that used train data set, and than we can use validation data set on the trained model to predict the result and determine MAE. Bellow is the function that calculates MAE values.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that helps get MAE scores\n",
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    #define model\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes = max_leaf_nodes, random_state = 0)\n",
    "    #fit model\n",
    "    model.fit(train_X, train_y)\n",
    "    #predict values \n",
    "    predict_vals = model.predict(val_X)\n",
    "    #calculate MAE\n",
    "    mae = mean_absolute_error(val_y, predict_vals)\n",
    "    return (mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now we have list of number of leaves. We can run 'for-loop' to compare each leaf MAE result. This helps to determine the lowest MAE and optimal number of leaves.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Leaf #: 5 \t\t MAE: 35044\nLeaf #: 25 \t\t MAE: 29016\nLeaf #: 50 \t\t MAE: 27405\nLeaf #: 100 \t\t MAE: 27282\nLeaf #: 250 \t\t MAE: 27893\nLeaf #: 500 \t\t MAE: 29454\n"
     ]
    }
   ],
   "source": [
    "#number of possible leaves\n",
    "candidate_max_leaf_nodes = [5, 25, 50, 100, 250, 500]\n",
    "\n",
    "#use for loop to compare MAE of different numbers of leaves\n",
    "for max_leaf_nodes in candidate_max_leaf_nodes:\n",
    "    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n",
    "    print (\"Leaf #: %d \\t\\t MAE: %d\" %(max_leaf_nodes, my_mae))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The above approach is good for small list of leaves. To avoid serching for result by hand, we can automatically determine the best number of leaves we can use dictinary approach.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best tree size: 100\n"
     ]
    }
   ],
   "source": [
    "#can use dictinary to determine lowest MAE\n",
    "scores = {leaf_size: get_mae(leaf_size, train_X, val_X, train_y, val_y) for leaf_size in candidate_max_leaf_nodes}\n",
    "\n",
    "#determones lowest MAE from dictinary\n",
    "best_tree_size = min(scores, key = scores.get)\n",
    "print('Best tree size:', best_tree_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now we have the best number of leaves (tree size), we can fit model using the whole data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_leaf_nodes=100, random_state=1)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "#final model using 100 leaves\n",
    "final_model = DecisionTreeRegressor(max_leaf_nodes = best_tree_size, random_state = 1)\n",
    "\n",
    "#fit model on the whole data\n",
    "final_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
